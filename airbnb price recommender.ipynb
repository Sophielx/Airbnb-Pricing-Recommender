{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiHA0kuiVQDn"
      },
      "source": [
        "Data 102 Final Project - US Airbnb Listing Price Recommender\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nwf62SulV0B",
        "outputId": "791e89e0-93a4-4a76-8367-7bb8089baf20"
      },
      "source": [
        "!pip install geopandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geopandas\n",
            "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 14.4 MB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 57.3 MB/s \n",
            "\u001b[?25hCollecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.0)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.19.5)\n",
            "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf_qOH4d003h",
        "outputId": "c294e5b2-bdca-4171-8d6a-a1a0ac68cb09"
      },
      "source": [
        "!pip install folium"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: folium in /usr/local/lib/python3.7/dist-packages (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from folium) (2.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from folium) (1.19.5)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium) (0.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from folium) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium) (2.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->folium) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZjdXitGlbng"
      },
      "source": [
        "import geopandas as gpd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwwKUYcEvitX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style = \"whitegrid\", \n",
        "        color_codes = True,\n",
        "        font_scale = 1.5)\n",
        "sns.set_palette('Reds') \n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csZFxQIhOZ9V"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvzBkYNIvi3y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "1a400f2a-64f2-4025-cd35-d2ffdb1dd3e6"
      },
      "source": [
        "airbnb_json = pd.read_json(\"airbnb-listings.json\", orient = 'records')\n",
        "airbnb_json.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2d27c3825125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mairbnb_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"airbnb-listings.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mairbnb_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1138\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m             )\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unmatched ''\"' when when decoding 'string'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9TgQZqEzAWD"
      },
      "source": [
        "airbnb = pd.json_normalize(airbnb_json.fields)\n",
        "airbnb.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUbLR-GIgCjz"
      },
      "source": [
        "airbnb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiH9wyPG3Is7"
      },
      "source": [
        "airbnb.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ7TkIda4jVs"
      },
      "source": [
        "info = ['id', 'name', 'host_id', 'host_name', 'host_since', 'host_total_listings_count', 'neighbourhood_cleansed', 'city', 'state', 'market', 'country_code', 'latitude',\n",
        "'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'amenities', 'price', 'weekly_price', 'monthly_price','minimum_nights', 'maximum_nights', 'number_of_reviews',\n",
        "'review_scores_rating', 'reviews_per_month', 'cancellation_policy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3siUiq56DNXJ"
      },
      "source": [
        "filtered_airbnb = airbnb[info]\n",
        "filtered_airbnb.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmN1Da8P_Dnl"
      },
      "source": [
        "filtered_airbnb.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_9IDXp0yj3I"
      },
      "source": [
        "##sophie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG7cQ1BpzOzd"
      },
      "source": [
        "filtered_airbnb['amenities'] = filtered_airbnb['amenities'].str.split(',')\n",
        "filtered_airbnb = filtered_airbnb[filtered_airbnb[\"amenities\"].notna()]\n",
        "\n",
        "# amenity_list = filtered_airbnb['amenities'].explode().unique()\n",
        "\n",
        "# for newcol in amenity_list:\n",
        "#     filtered_airbnb[newcol]= filtered_airbnb['amenities'].apply(lambda x: any([newcol in x])).astype(int)\n",
        "# filtered_airbnb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNlp8WrYwiU2"
      },
      "source": [
        "filtered_airbnb['state'] = filtered_airbnb['state'].str.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6W9c_-Mz3d5"
      },
      "source": [
        "filtered_airbnb.isna().sum()[filtered_airbnb.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYG2J3z13Ksr"
      },
      "source": [
        "#Jenna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1wTqD5m1uzX"
      },
      "source": [
        "filtered_airbnb[\"review_scores_rating\"] = filtered_airbnb[\"review_scores_rating\"].fillna(filtered_airbnb.groupby(\"host_id\")[\"review_scores_rating\"].transform(\"mean\"))\n",
        "filtered_airbnb[\"reviews_per_month\"] = filtered_airbnb[\"reviews_per_month\"].fillna(filtered_airbnb.groupby(\"host_id\")[\"reviews_per_month\"].transform(\"mean\"))\n",
        "\n",
        "filtered_airbnb[\"review_scores_rating\"] = filtered_airbnb[\"review_scores_rating\"].fillna(filtered_airbnb.groupby(\"neighbourhood_cleansed\")[\"review_scores_rating\"].transform(\"mean\"))\n",
        "filtered_airbnb[\"reviews_per_month\"] = filtered_airbnb[\"reviews_per_month\"].fillna(filtered_airbnb.groupby(\"neighbourhood_cleansed\")[\"reviews_per_month\"].transform(\"mean\"))\n",
        "\n",
        "filtered_airbnb[\"review_scores_rating\"] = filtered_airbnb[\"review_scores_rating\"].fillna(filtered_airbnb.groupby(\"city\")[\"review_scores_rating\"].transform(\"mean\"))\n",
        "filtered_airbnb[\"reviews_per_month\"] = filtered_airbnb[\"reviews_per_month\"].fillna(filtered_airbnb.groupby(\"city\")[\"reviews_per_month\"].transform(\"mean\"))\n",
        "\n",
        "filtered_airbnb[\"review_scores_rating\"] = filtered_airbnb[\"review_scores_rating\"].fillna(filtered_airbnb.groupby([\"state\"])[\"review_scores_rating\"].transform(\"mean\"))\n",
        "filtered_airbnb[\"reviews_per_month\"] = filtered_airbnb[\"reviews_per_month\"].fillna(filtered_airbnb.groupby([\"state\"])[\"reviews_per_month\"].transform(\"mean\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRYQSme82CdT"
      },
      "source": [
        "filtered_airbnb = filtered_airbnb[filtered_airbnb[\"market\"].notna()]\n",
        "filtered_airbnb = filtered_airbnb[filtered_airbnb[\"property_type\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy4Bqpwg3T0P"
      },
      "source": [
        "filtered_airbnb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhDXUrxg3Xik"
      },
      "source": [
        "filtered_airbnb.isna().sum()[filtered_airbnb.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7jC3gQG3Q7H"
      },
      "source": [
        "#sophia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b8bS_sCyojK"
      },
      "source": [
        "filtered_airbnb = filtered_airbnb[filtered_airbnb[\"host_since\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k3BsYNe5hqr"
      },
      "source": [
        "filtered_airbnb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBaX-kN-5pEi"
      },
      "source": [
        "filtered_airbnb.isna().sum()[filtered_airbnb.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvPaM4WCysV9"
      },
      "source": [
        "import re\n",
        "filtered_airbnb = filtered_airbnb[filtered_airbnb[\"city\"].notna()]\n",
        "filtered_airbnb = filtered_airbnb[filtered_airbnb.city.str.contains(\"^[a-zA-Z]\")]\n",
        "filtered_airbnb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZPCFYD65zEi"
      },
      "source": [
        "filtered_airbnb.isna().sum()[filtered_airbnb.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg75Oei42VNJ"
      },
      "source": [
        "# Ziyue "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O2AyW7jswcj"
      },
      "source": [
        "new_price = filtered_airbnb.groupby('neighbourhood_cleansed')['price'].apply(lambda x: x.fillna(x.mean()))\n",
        "filtered_airbnb['price'] = new_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH40a0_XvBX1"
      },
      "source": [
        "filtered_airbnb['price'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1RFxxbOwEKO"
      },
      "source": [
        "new_price_city = filtered_airbnb.groupby('market')['price'].apply(lambda x: x.fillna(x.mean()))\n",
        "filtered_airbnb['price'] = new_price_city"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD1P8FqbwKS3"
      },
      "source": [
        "filtered_airbnb.isna().sum()[filtered_airbnb.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmhdNuRPvTWc"
      },
      "source": [
        "new_bathroom = filtered_airbnb.groupby('property_type')['bathrooms'].apply(lambda x: x.fillna(x.mean()))\n",
        "filtered_airbnb['bathrooms'] = new_bathroom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDa5uDImxUws"
      },
      "source": [
        "filtered_airbnb['bathrooms'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqeUouaJx1JK"
      },
      "source": [
        "filtered_airbnb = filtered_airbnb[filtered_airbnb[\"bathrooms\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFsD_90FxWjl"
      },
      "source": [
        "new_bedroom = filtered_airbnb.groupby('property_type')['bedrooms'].apply(lambda x: x.fillna(x.mean()))\n",
        "filtered_airbnb['bedrooms'] = new_bedroom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgjQv6fLxd8w"
      },
      "source": [
        "filtered_airbnb['bedrooms'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr4f6gu8xf-p"
      },
      "source": [
        "new_bed = filtered_airbnb.groupby('property_type')['beds'].apply(lambda x: x.fillna(x.mean()))\n",
        "filtered_airbnb['beds'] = new_bed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brctg8JAxxaZ"
      },
      "source": [
        "filtered_airbnb['beds'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfrOiNWO8uhf"
      },
      "source": [
        "filtered_airbnb.isna().sum()[filtered_airbnb.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd5NXgzM_Tho"
      },
      "source": [
        "filtered_airbnb = filtered_airbnb[filtered_airbnb[\"accommodates\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4jyF4T_AB7f"
      },
      "source": [
        "#extract features and target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVOWEcWg9wgW"
      },
      "source": [
        "features = filtered_airbnb.drop(columns=['id',\t'name',\t'host_id','host_name','weekly_price','monthly_price','price','country_code'])\n",
        "features.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuuckl2J-5Yw"
      },
      "source": [
        "features.isna().sum()[filtered_airbnb.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh3Dm2VcajBz"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DZH8aeSaJBE"
      },
      "source": [
        "#feature engineering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddu8PuzP6pOh"
      },
      "source": [
        "features['latitude']= features['latitude'].astype(float)\n",
        "features['longitude']= features['longitude'].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "190yiOBHaE9q"
      },
      "source": [
        "list1 = [str(i).split(\"-\") for i in features[\"host_since\"]]\n",
        "list2 = [(2022-int(i[0])) for i in list1]\n",
        "features[\"host_years\"] = list2\n",
        "features = features.drop(columns = [\"host_since\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0B8W3LZZKFQ"
      },
      "source": [
        "amenity_list = features['amenities'].explode().unique()\n",
        "\n",
        "for newcol in amenity_list:\n",
        "    features[newcol]= features['amenities'].apply(lambda x: any([newcol in x])).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A799t7_Eacze"
      },
      "source": [
        "features.shape #111 new feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpiWl8rr_mjA"
      },
      "source": [
        "neigh = pd.get_dummies(features[[\"neighbourhood_cleansed\"]], prefix=\"neighbourhood_cleansed\")\n",
        "city = pd.get_dummies(features[[\"city\"]], prefix=\"city\")\n",
        "state = pd.get_dummies(features[[\"state\"]], prefix=\"state\")\n",
        "market = pd.get_dummies(features[[\"market\"]], prefix=\"market\")\n",
        "proper = pd.get_dummies(features[[\"property_type\"]], prefix=\"property_type\")\n",
        "room = pd.get_dummies(features[[\"room_type\"]], prefix=\"room_type\")\n",
        "cancel = pd.get_dummies(features[[\"cancellation_policy\"]], prefix=\"cancellation_policy\")\n",
        "features2 = features.drop(columns = [\"neighbourhood_cleansed\", \"city\", \"state\", \"market\", \"property_type\", \"room_type\", \"cancellation_policy\", \"amenities\"])\n",
        "features2 = pd.concat([neigh, city, state, market, proper, room, cancel, features2], axis = 1)\n",
        "features3 = features.drop(columns = [\"neighbourhood_cleansed\", \"city\", \"state\", \"market\", \"property_type\", \"room_type\", \"cancellation_policy\", \"amenities\"])\n",
        "features3 = pd.concat([market, proper, room, cancel, features3], axis = 1)\n",
        "features2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features[['market']]"
      ],
      "metadata": {
        "id": "59-hGJ-VEFEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Acr9ZEYgETv_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-luqpNBp32m"
      },
      "source": [
        "features.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZZBKx92BCsc"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ws_LyRh-Na5"
      },
      "source": [
        "target = filtered_airbnb[[\"price\"]]\n",
        "target.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDBOSdDE_bLr"
      },
      "source": [
        "target.isna().sum()[target.isna().sum() > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqiPfx7PbGa_"
      },
      "source": [
        "#Data Exploration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XFX1_QusZYW"
      },
      "source": [
        "#Data Visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kInWDkU5jeBl"
      },
      "source": [
        "map = gpd.read_file('cb_2018_us_state_500k.shp')\n",
        "map.plot(figsize=(10, 10))\n",
        "plt.xlim(-180,-60);\n",
        "plt.ylim(10,75);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbba-L_Ennrw"
      },
      "source": [
        "map.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgR03RKqo80F"
      },
      "source": [
        "#merge the map dataframe with feature dataframe\n",
        "merged = map.set_index('STUSPS').merge(filtered_airbnb, how='left', left_on=\"STUSPS\", right_on=\"state\")\n",
        "merged = merged.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5lZEpmpbqU"
      },
      "source": [
        "# set a variable that will call whatever column we want to visualise on the map\n",
        "variable = 'price'\n",
        "# create figure and axes for Matplotlib\n",
        "fig, ax = plt.subplots(1, figsize=(15, 10))\n",
        "# create map\n",
        "merged.plot(column=variable, cmap='Reds', linewidth=0.8, ax=ax, legend=True, edgecolor='0.8',figsize=(15, 10))\n",
        "plt.xlim(-180,-60)\n",
        "plt.ylim(10,75)\n",
        "plt.title('Airbnb Listing Price in US')\n",
        "plt.xlabel('latitude')\n",
        "plt.ylabel('longtitude');\n",
        "#fig.savefig(\"map.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VH-_f4e0xoo"
      },
      "source": [
        "import folium\n",
        "from folium import Choropleth, Circle, Marker\n",
        "from folium.plugins import HeatMap, MarkerCluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0eGL7D06RF"
      },
      "source": [
        "# Create an interactive map\n",
        "m_4 = folium.Map(location=[42.32,-71.0589], tiles='cartodbpositron', zoom_start=13)\n",
        "\n",
        "def color_producer(val):\n",
        "    if val <= 100:\n",
        "        return 'forestgreen'\n",
        "    else:\n",
        "        return 'darkred'\n",
        "\n",
        "# Add a bubble map to the base map\n",
        "for i in range(0,len(filtered_airbnb)):\n",
        "    Circle(\n",
        "        location=[float(filtered_airbnb.iloc[i]['latitude']), float(filtered_airbnb.iloc[i]['longitude'])],\n",
        "        radius=20,\n",
        "        color=color_producer(filtered_airbnb.iloc[i]['price'])).add_to(m_4)\n",
        "\n",
        "# Display the map\n",
        "m_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmLsPhcNPc0u"
      },
      "source": [
        "filtered_airbnb.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnz2ZfegP4Ey"
      },
      "source": [
        "g = sns.swarmplot(y = \"market\",\n",
        "              x = 'price', \n",
        "              data = filtered_airbnb,\n",
        "              # Decrease the size of the points to avoid crowding \n",
        "              size = 4)\n",
        "g.figure.set_size_inches(18,20)\n",
        "plt.show()\n",
        "\n",
        "fig = g.get_figure()\n",
        "fig.savefig(\"market2.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyEeCiRMQJ29"
      },
      "source": [
        "g = sns.swarmplot(y = \"property_type\",\n",
        "              x = 'price', \n",
        "              data = filtered_airbnb,\n",
        "              # Decrease the size of the points to avoid crowding \n",
        "              size = 4)\n",
        "g.figure.set_size_inches(17,20)\n",
        "plt.show()\n",
        "\n",
        "fig = g.get_figure()\n",
        "fig.savefig(\"property_type.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_6SevfWluM_"
      },
      "source": [
        "g = sns.swarmplot(y = \"room_type\",\n",
        "              x = 'price', \n",
        "              data = filtered_airbnb)\n",
        "g.figure.set_size_inches(10,7)\n",
        "plt.show()\n",
        "\n",
        "fig = g.get_figure()\n",
        "fig.savefig(\"room_type.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMR4tSv3l0h9"
      },
      "source": [
        "g = sns.swarmplot(y = \"cancellation_policy\",\n",
        "              x = 'price', \n",
        "              data = filtered_airbnb,\n",
        "              # Decrease the size of the points to avoid crowding \n",
        "              size = 5)\n",
        "g.figure.set_size_inches(13,7)\n",
        "plt.show()\n",
        "\n",
        "fig = g.get_figure()\n",
        "fig.savefig(\"cancellation_policy.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIX0ZMVtsZbO"
      },
      "source": [
        "#Heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKFyVYfvNUI"
      },
      "source": [
        "features = pd.concat([target['price'], features], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhS4Q542sZfK"
      },
      "source": [
        "import numpy as np; np.random.seed(0)\n",
        "import seaborn as sns; sns.set_theme()\n",
        "dataplot = sns.heatmap(features[[\"host_years\", \"host_total_listings_count\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\",\"price\"]].corr(), cmap=\"YlGnBu\", annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrpbWzXI1vQ7"
      },
      "source": [
        "dataplot = sns.heatmap(features[[\"minimum_nights\",\"maximum_nights\", \"number_of_reviews\",\"review_scores_rating\", \"reviews_per_month\",\"price\"]].corr(), cmap=\"YlGnBu\", annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDsiVi_Kwug3"
      },
      "source": [
        "features['market'].unique().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8vkPEC-x4hv"
      },
      "source": [
        "pair_1 = features[[\"price\", \"market\",\"host_years\", \"host_total_listings_count\"]]\n",
        "sns.pairplot(pair_1, hue = 'market', diag_kind = 'kde',\n",
        "             plot_kws = {'alpha': 0.6, 's': 80, 'edgecolor': 'k'},\n",
        "             size = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_MXES0ryZnr"
      },
      "source": [
        "pair_2 = features[[\"price\", \"market\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"minimum_nights\"]]\n",
        "sns.pairplot(pair_2, hue = 'market', diag_kind = 'kde',\n",
        "             plot_kws = {'alpha': 0.6, 's': 80, 'edgecolor': 'k'},\n",
        "             size = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "len61pkIyfDg"
      },
      "source": [
        "pair_3 = features[[\"price\", \"market\", \"number_of_reviews\",\"review_scores_rating\", \"reviews_per_month\"]]\n",
        "sns.pairplot(pair_3, hue = 'market', diag_kind = 'kde',\n",
        "             plot_kws = {'alpha': 0.6, 's': 80, 'edgecolor': 'k'},\n",
        "             size = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jxMiI0A6Lm_"
      },
      "source": [
        "#drop irrelevant columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWnn-b246hjc"
      },
      "source": [
        "features3 = features3.drop(columns = [\"host_years\", \"host_total_listings_count\", \"minimum_nights\", \"maximum_nights\",\"review_scores_rating\", \"latitude\", \"longitude\"])\n",
        "pd.set_option('max_columns', 2000)\n",
        "features3.head(100)\n",
        "for i in features3[amenity_list].columns:\n",
        "  if sum(features3[i]) < 500:\n",
        "    features3 = features3.drop(columns = [i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5tzubZM-zul"
      },
      "source": [
        "features3 = features3.drop(columns = [\"translation missing: en.hosting_amenity_49\", \"translation missing: en.hosting_amenity_50\"])\n",
        "features3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKQJHPTZIrCk"
      },
      "source": [
        "# eliminate outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lODqrcyfIuwo"
      },
      "source": [
        "def outlier_treatment(data):\n",
        " sorted(data)\n",
        " Q1,Q3 = np.percentile(data , [25,75])\n",
        " IQR = Q3-Q1\n",
        " lower_range = Q1-(1.5 * IQR)\n",
        " upper_range = Q3+(1.5 * IQR)\n",
        " return lower_range,upper_range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK8VHdDYIwuT"
      },
      "source": [
        "combined = pd.concat([target[\"price\"], features3], axis = 1)\n",
        "lowerbound,upperbound = outlier_treatment(combined[\"price\"])\n",
        "combined[(combined.price < lowerbound)|(combined.price > upperbound)]\n",
        "\n",
        "combined.drop(combined[(combined.price < lowerbound)|(combined.price > upperbound)].index , inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axQsUumkIybq"
      },
      "source": [
        "plt.hist(combined.price)\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Prices')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ZvMu0ZI08H"
      },
      "source": [
        "plt.hist(target.price)\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Prices')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFWczYbiI5hJ"
      },
      "source": [
        "target = combined.price\n",
        "features3 = combined.drop(columns = [\"price\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJHEYSik_hSh"
      },
      "source": [
        "#split our data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4N9mQFxyv3r"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features3, target, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbg-GJGTvvGb"
      },
      "source": [
        "#Machine Learning Methods"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdcs61Lyjpe3"
      },
      "source": [
        "#Linear Regression (KL)\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=reg.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=reg.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "# r2 = r2_score(y_train, y_pred_train)\n",
        "# print('R2 score of training---')\n",
        "# print(r2)\n",
        "r2_val_score = cross_val_score(reg, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))\n",
        "\n",
        "# print('---normalized---')\n",
        "\n",
        "# #normalized value\n",
        "# reg.fit(normalize(X_train), y_train)\n",
        "# print('Mean Squared Error of training---')\n",
        "# y_pred_train=reg.predict(normalize(X_train))\n",
        "# print(mean_squared_error(y_train, y_pred_train))\n",
        "# y_pred_test=reg.predict(normalize(X_test))\n",
        "# print('Mean Squared Error of test---')\n",
        "# print(mean_squared_error(y_test, y_pred_test))\n",
        "# # r2 = r2_score(y_train, y_pred_train)\n",
        "# # print('R2 score of training---')\n",
        "# # print(r2)\n",
        "# r2_val_score = cross_val_score(reg, X_train, y_train, cv=5, scoring='r2')\n",
        "# print('R2 cross validation score of training---')\n",
        "# print(r2_val_score)\n",
        "# print('R2 mean cross validation score of training---')\n",
        "# print(r2_val_score.mean())\n",
        "# print('R2 score of test---')\n",
        "# print(r2_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tWtG9Z5ptSO"
      },
      "source": [
        "#regressors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaAK7XSqNWG"
      },
      "source": [
        "bag = BaggingRegressor()\n",
        "bag.fit(X_train, y_train)\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=bag.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=bag.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "# r2 = r2_score(y_train, y_pred_train)\n",
        "# print('R2 score of training---')\n",
        "# print(r2)\n",
        "r2_val_score = cross_val_score(bag, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))\n",
        "\n",
        "# print('---normalized---')\n",
        "\n",
        "# #normalized value\n",
        "# bag.fit(normalize(X_train), y_train)\n",
        "# print('Mean Squared Error of training---')\n",
        "# y_pred_train=bag.predict(normalize(X_train))\n",
        "# print(mean_squared_error(y_train, y_pred_train))\n",
        "# y_pred_test=bag.predict(normalize(X_test))\n",
        "# print('Mean Squared Error of test---')\n",
        "# print(mean_squared_error(y_test, y_pred_test))\n",
        "# # r2 = r2_score(y_train, y_pred_train)\n",
        "# # print('R2 score of training---')\n",
        "# # print(r2)\n",
        "# r2_val_score = cross_val_score(bag, X_train, y_train, cv=5, scoring='r2')\n",
        "# print('R2 cross validation score of training---')\n",
        "# print(r2_val_score)\n",
        "# print('R2 mean cross validation score of training---')\n",
        "# print(r2_val_score.mean())\n",
        "# print('R2 score of test---')\n",
        "# print(r2_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7kn0jiZU0nH"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Setup the hyperparameter grid\n",
        "param = {\"n_estimators\": np.arange(100,500,100)}\n",
        "\n",
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "cv = RandomizedSearchCV(bag, param, cv=5, scoring='r2')\n",
        "\n",
        "# Fit it to the data\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Bagging Regressor Parameters: {}\".format(cv.best_params_)) \n",
        "print(\"Best score is {}\".format(cv.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimal bagging\n",
        "bag = BaggingRegressor(n_estimators=400)\n",
        "\n",
        "bag.fit(X_train, y_train)\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=bag.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=bag.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "r2_val_score = cross_val_score(bag, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "ssyC4B025oin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6C5qKq5qv-7"
      },
      "source": [
        "adaboost = AdaBoostRegressor()\n",
        "adaboost.fit(X_train, y_train)\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=adaboost.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=adaboost.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "# r2 = r2_score(y_train, y_pred_train)\n",
        "# print('R2 score of training---')\n",
        "# print(r2)\n",
        "r2_val_score = cross_val_score(adaboost, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))\n",
        "\n",
        "# print('---normalized---')\n",
        "\n",
        "# #normalized value\n",
        "# adaboost.fit(normalize(X_train), y_train)\n",
        "# print('Mean Squared Error of training---')\n",
        "# y_pred_train=adaboost.predict(normalize(X_train))\n",
        "# print(mean_squared_error(y_train, y_pred_train))\n",
        "# y_pred_test=adaboost.predict(normalize(X_test))\n",
        "# print('Mean Squared Error of test---')\n",
        "# print(mean_squared_error(y_test, y_pred_test))\n",
        "# # r2 = r2_score(y_train, y_pred_train)\n",
        "# # print('R2 score of training---')\n",
        "# # print(r2)\n",
        "# r2_val_score = cross_val_score(adaboost, X_train, y_train, cv=5, scoring='r2')\n",
        "# print('R2 cross validation score of training---')\n",
        "# print(r2_val_score)\n",
        "# print('R2 mean cross validation score of training---')\n",
        "# print(r2_val_score.mean())\n",
        "# print('R2 score of test---')\n",
        "# print(r2_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the hyperparameter grid\n",
        "param = {\"n_estimators\": np.arange(100,500,100),\n",
        "         \"loss\":[\"linear\", \"square\", \"exponential\"]}\n",
        "\n",
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "cv = RandomizedSearchCV(adaboost, param, cv=5, scoring='r2')\n",
        "\n",
        "# Fit it to the data\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned AdaBoost Regressor Parameters: {}\".format(cv.best_params_)) \n",
        "print(\"Best score is {}\".format(cv.best_score_))"
      ],
      "metadata": {
        "id": "mmQ49Obk5jmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimal adaboost\n",
        "adaboost = AdaBoostRegressor(n_estimators=100, loss='linear')\n",
        "adaboost.fit(X_train, y_train)\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=adaboost.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=adaboost.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "r2_val_score = cross_val_score(adaboost, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "tGS3nCzo532-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUpxxPkb2C2D"
      },
      "source": [
        "#Decision Trees Regressor (SJ)\n",
        "#original value\n",
        "regressor = DecisionTreeRegressor(random_state = 42, max_depth = 100) \n",
        "regressor.fit(X_train, y_train)\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=regressor.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=regressor.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "# r2 = r2_score(y_train, y_pred_train)\n",
        "# print('R2 score of training---')\n",
        "# print(r2)\n",
        "r2_val_score = cross_val_score(regressor, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))\n",
        "\n",
        "# print('---normalized---')\n",
        "\n",
        "# #normalized value\n",
        "# regressor.fit(normalize(X_train), y_train)\n",
        "# print('Mean Squared Error of training---')\n",
        "# y_pred_train=regressor.predict(normalize(X_train))\n",
        "# print(mean_squared_error(y_train, y_pred_train))\n",
        "# y_pred_test=regressor.predict(normalize(X_test))\n",
        "# print('Mean Squared Error of test---')\n",
        "# print(mean_squared_error(y_test, y_pred_test))\n",
        "# # r2 = r2_score(y_train, y_pred_train)\n",
        "# # print('R2 score of training---')\n",
        "# # print(r2)\n",
        "# r2_val_score = cross_val_score(regressor, X_train, y_train, cv=5, scoring='r2')\n",
        "# print('R2 cross validation score of training---')\n",
        "# print(r2_val_score)\n",
        "# print('R2 mean cross validation score of training---')\n",
        "# print(r2_val_score.mean())\n",
        "# print('R2 score of test---')\n",
        "# print(r2_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the hyperparameter grid\n",
        "param_dist = {\"max_depth\": np.arange(1, regressor.tree_.max_depth+1),\n",
        "              \"max_features\": np.arange(1,10),\n",
        "              \"min_samples_leaf\": np.arange(1, 10)}\n",
        "\n",
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "cv = GridSearchCV(regressor, param_dist, cv=5, scoring='r2')\n",
        "\n",
        "# Fit it to the data\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Decision Tree Regression Parameters: {}\".format(cv.best_params_)) \n",
        "print(\"Best score is {}\".format(cv.best_score_))"
      ],
      "metadata": {
        "id": "KqZWjXA46AkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimal tree\n",
        "regressor = DecisionTreeRegressor(max_depth= 9, max_features=8, min_samples_leaf=6) \n",
        "regressor.fit(X_train, y_train)\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=regressor.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=regressor.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "r2_val_score = cross_val_score(regressor, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "6qjH9wt06bzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4chHmDBu2dAO"
      },
      "source": [
        "#Random Forest Regressor (JY)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(max_features=5, min_samples_leaf=5, \n",
        "                           n_estimators = 500, random_state=88)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=rf.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=rf.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "# r2 = r2_score(y_train, y_pred_train)\n",
        "# print('R2 score of training---')\n",
        "# print(r2)\n",
        "r2_val_score = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))\n",
        "\n",
        "# print('---normalized---')\n",
        "\n",
        "# print('Mean Squared Error of training---')\n",
        "# y_pred_train=rf.predict(normalize(X_train))\n",
        "# print(mean_squared_error(y_train, y_pred_train))\n",
        "# y_pred_test=rf.predict(normalize(X_test))\n",
        "# print('Mean Squared Error of test---')\n",
        "# print(mean_squared_error(y_test, y_pred_test))\n",
        "# # r2 = r2_score(y_train, y_pred_train)\n",
        "# # print('R2 score of training---')\n",
        "# # print(r2)\n",
        "# r2_val_score = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2')\n",
        "# print('R2 cross validation score of training---')\n",
        "# print(r2_val_score)\n",
        "# print('R2 mean cross validation score of training---')\n",
        "# print(r2_val_score.mean())\n",
        "# print('R2 score of test---')\n",
        "# print(r2_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the hyperparameter grid\n",
        "param = {\"max_depth\": np.arange(1, 32),\n",
        "              \"max_features\": np.arange(1,10),\n",
        "              \"min_samples_leaf\": np.arange(1, 10),\n",
        "              \"n_estimators\": np.arange(100,500,100)}\n",
        "\n",
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "cv = RandomizedSearchCV(rf, param, cv=5, scoring='r2')\n",
        "\n",
        "# Fit it to the data\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Random Forest Regression Parameters: {}\".format(cv.best_params_)) \n",
        "print(\"Best score is {}\".format(cv.best_score_))"
      ],
      "metadata": {
        "id": "ducHH1VM6kcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimal forest\n",
        "rf = RandomForestRegressor(n_estimators=300, min_samples_leaf=1, max_features=9, max_depth=19)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=rf.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=rf.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "r2_val_score = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "1LJrNyJ96o0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2dG_Xbr2Eh4"
      },
      "source": [
        "#Neural Network (KL)\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "clf = MLPRegressor(hidden_layer_sizes=(500, 200), max_iter=100, activation='relu', learning_rate_init=0.1,\n",
        "                   solver = 'adam',  random_state=42, verbose=10)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_train=clf.predict(X_train)\n",
        "\n",
        "print('Mean Squared Error of training---')\n",
        "print(metrics.mean_squared_error(y_train, y_pred_train))\n",
        "print('R2 on training---')\n",
        "print(metrics.r2_score(y_train,predictions))\n",
        "\n",
        "print('---normalized---')\n",
        "\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=clf.predict(normalize(X_train))\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=clf.predict(normalize(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf6UFT84MAbZ"
      },
      "source": [
        "\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(metrics.mean_squared_error(y_test, y_pred_test))\n",
        "print('R2 on test---')\n",
        "print(metrics.r2_score(y_test),y_pred_test))\n",
        "\n",
        "print('---normalized---')\n",
        "\n",
        "y_pred_test=clf.predict(normalize(X_test))\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHgfSEiTVqYQ"
      },
      "source": [
        "# Neural Network with Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkEbPfRYVtEF"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.random.set_seed(1)\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(123, input_dim=109, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(2670, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU7McytlVu-4"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=150, verbose=1, validation_split=0.2)\n",
        "predictions = model.predict(X_train)\n",
        "print('R2 on train---')\n",
        "print(metrics.r2_score(y_train,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hhpG54zX73R"
      },
      "source": [
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='middle')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89eFo8NodK6m"
      },
      "source": [
        "# \"MSE\"\n",
        "plt.plot(history.history['mse'])\n",
        "plt.title('Model MSE')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='middle')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l6GDcxiePMx"
      },
      "source": [
        "plt.savefig(\"mse.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8nAhVyYkEFH"
      },
      "source": [
        "# Producing a dataframe of feature importances\n",
        "ft_weights_xgb_reg = pd.DataFrame(model.feature_importances_, columns=['weight'], index=X_train.columns)\n",
        "ft_weights_xgb_reg.sort_values('weight', inplace=True)\n",
        "\n",
        "# Plotting feature importances\n",
        "plt.figure(figsize=(8,20))\n",
        "plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
        "plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
        "plt.xlabel(\"Feature importance\")\n",
        "plt.margins(y=0.01)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzriF7w6BCuO"
      },
      "source": [
        "#SVM (JY)\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "svm = svm.SVR(kernel='rbf')\n",
        "svm = svm.fit(X_train, y_train)\n",
        "\n",
        "print('Mean Squared Error of training---')\n",
        "y_pred_train=svm.predict(X_train)\n",
        "print(mean_squared_error(y_train, y_pred_train))\n",
        "y_pred_test=svm.predict(X_test)\n",
        "print('Mean Squared Error of test---')\n",
        "print(mean_squared_error(y_test, y_pred_test))\n",
        "# r2 = r2_score(y_train, y_pred_train)\n",
        "# print('R2 score of training---')\n",
        "# print(r2)\n",
        "r2_val_score = cross_val_score(svm, X_train, y_train, cv=5, scoring='r2')\n",
        "print('R2 cross validation score of training---')\n",
        "print(r2_val_score)\n",
        "print('R2 mean cross validation score of training---')\n",
        "print(r2_val_score.mean())\n",
        "print('R2 score of test---')\n",
        "print(r2_score(y_test, y_pred_test))\n",
        "\n",
        "# print('---normalized---')\n",
        "\n",
        "# print('Mean Squared Error of training---')\n",
        "# y_pred_train=svm.predict(normalize(X_train))\n",
        "# print(mean_squared_error(y_train, y_pred_train))\n",
        "# y_pred_test=svm.predict(normalize(X_test))\n",
        "# print('Mean Squared Error of test---')\n",
        "# print(mean_squared_error(y_test, y_pred_test))\n",
        "# # r2 = r2_score(y_train, y_pred_train)\n",
        "# # print('R2 score of training---')\n",
        "# # print(r2)\n",
        "# r2_val_score = cross_val_score(svm, X_train, y_train, cv=5, scoring='r2')\n",
        "# print('R2 cross validation score of training---')\n",
        "# print(r2_val_score)\n",
        "# print('R2 mean cross validation score of training---')\n",
        "# print(r2_val_score.mean())\n",
        "# print('R2 score of test---')\n",
        "# print(r2_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the hyperparameter grid\n",
        "param = {'C': [0.1,1, 10, 100], \n",
        "              'gamma': [1,0.1,0.01,0.001],\n",
        "              'kernel': ['rbf', 'poly']}\n",
        "\n",
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "cv = RandomizedSearchCV(svm, param, cv=5, scoring='r2')\n",
        "\n",
        "# Fit it to the data\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned SVM Parameters: {}\".format(cv.best_params_)) \n",
        "print(\"Best score is {}\".format(cv.best_score_))"
      ],
      "metadata": {
        "id": "9j4pYPXB65Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgk6tEKju9G4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}